\chapter*{Sommario} % senza numerazione
\label{sommario}

\addcontentsline{toc}{chapter}{Sommario} % da aggiungere comunque all'indice

L'oggetto di questa tesi è lo sviluppo di un sistema di cattura e registrazione multimediale di lezioni universitarie, conferenze e seminari. Il sistema prodotto si basa su un dispositivo fisico dotato di apposito hardware per la cattura video, sul quale viene eseguito un apposito software su sistema operativo Android.

Il sistema è stato realizzato nell'ambito del progetto LODE (Lectures On DEmand) del professor Marco Ronchetti (Università di Trento), ed è stato elaborato durante un tirocinio formativo presso l'azienda AXIA STUDIO S.R.L., con l'obiettivo finale di affinare la soluzione e di immetterla sul mercato delle soluzioni IoT accademiche.

Il progetto LODE, nel cui contesto questo lavoro si inserisce, è un progetto sperimentale realizzato in diverse iterazioni presso l'Università di Trento, con l'obiettivo di fornire una soluzione low cost per l'acquisizione video delle lezioni universitarie. Le ultime versioni del sistema prevedono la possibilità di registrare flussi multimediali multipli, in particolare il video in uscita dal computer del docente, il video acquisito da una videocamera che riprende il docente e/o la lavagna, e l'audio di un microfono indossato dal docente.

Uno degli obiettivi principali del sistema è di essere sufficientemente semplice da poter essere comandato direttamente da un professore. Al termine della lezione, un processo di post-elaborazione automatizzabile si occupa di unire i flussi video e audio e di sincronizzarli, per ottenere i contenuti finali da pubblicare in una pagina web accessibile dagli studenti iscritti al corso.

Una funzionalità del sistema prevede anche che lo studente possa catturare durante le lezioni degli screenshot di ciò che viene proiettato in quel momento, con la possibilità di scrivere annotazioni testuali o di disegnare sulle catture.

Nella sua ultima iterazione, il sistema LODE prevede l'uso di un dispositivo fisico, soprannominato LodeBox, che incorpora un single-board computer (computer su una scheda) Raspberry Pi. Tramite apposite estensioni hardware, in particolare un modulo "HDMI to CSI-2", il dispositivo è in grado di acquisire un input HDMI come se si trattasse del video di una videocamera, e di sfruttare funzionalità come l'anteprima su schermo e la registrazione H.264 tramite encoder hardware. Il dispositivo prevede anche la possibilità di collegare un proiettore tramite uscita HDMI, un microfono tramite un adattatore USB, e una videocamera RTSP (Real Time Streaming Protocol) tramite la rete locale.

Questa soluzione si scontra però con delle difficoltà tecniche, che rendono difficile la realizzazione di un sistema affidabile e pronto per il pubblico. Tra le problematiche si evidenziano: la mancanza di storage integrato e duraturo ad alte prestazioni; la scarsa qualità del Wi-Fi; la difficoltà nel gestire situazioni "plug and play" come la disconnessione e la riconnessione del cavo HDMI, che richiederebbero di riavviare il dispositivo forzatamente; la difficoltà nel cambiare il branding software del dispositivo in modo che non sia evidente la presenza del sistema operativo Linux Raspbian.

%La verifica degli aspetti appena citati è stata la prima attività da me svolta, e ha portato ad alcuni miglioramenti, tra cui la notevole riduzione dello spazio di archiviazione richiesto per i file video.

Ci si è spostati quindi sulla ricerca di SBC (Single-Board Computer) alternative e più adatte per la realizzazione di applicazioni multimediali. La maggior parte delle SBC con funzioni multimediali è basata su sistema operativo Android, e in alcuni casi sono forniti SDK dedicati per sfruttare funzioni specifiche del dispositivo.

Gran parte del mio lavoro si è quindi concentrato sullo sviluppo di alcune applicazioni per Android, per verificare la fattibilità di una versione di LodeBox su hardware Android, utilizzando sia Kotlin che Java come linguaggi di programmazione.

La peculiarità fondamentale di molte board Android con input HDMI è che permettono di sfruttare direttamente le API di Android per l'acquisizione di video e immagini, consentendo quindi di scrivere codice che non sia strettamente legato all'hardware. Il sistema operativo Android prevede due versioni delle API per la "fotocamera", in particolare la classe \texttt{android.hardware.Camera} e le classi contenute in \texttt{android.hardware.camera2}. A partire da Android 5.0 (livello API 21), la classe \texttt{Camera} è deprecata ed è invece consigliato l'uso delle API \texttt{camera2}. Le differenze tra le due versioni sono notevoli: la seconda è più avanzata, ma anche più difficile da usare e non è garantito che ogni dispositivo con Android 5 o superiore la supporti a pieno. Esiste infatti una modalità \texttt{LEGACY} che dà la possibilità di usare le API \texttt{camera2} nonostante l'assenza di un supporto diretto a basso livello per le API.

È stato quindi necessario approfondire il funzionamento di entrambe le versioni delle API, per capire sia quale conviene usare in base all'hardware disponibile, sia quale è tecnicamente possibile usare per poter ottenere tutte le funzionalità richieste dal sistema LODE (ossia la proiezione del video in input, la registrazione in formato compresso e la cattura e invio di screenshot).

Oltre all'input HDMI, c'era la necessità di registrare anche il video di una videocamera esterna. Questa era raggiungibile tramite la rete locale e permetteva di acquisire il video da remoto tramite il protocollo di streaming RTSP. Di conseguenza, il flusso può essere registrato direttamente sulla board, utilizzando una versione della libreria \texttt{ffmpeg} compilata per funzionare su Android.

Un altro punto importante dello sviluppo di un'applicazione embedded per Android è la realizzazione di una modalità \textit{kiosk}, cioè una situazione in cui l'utilizzatore del sistema può utilizzare solo ed esclusivamente una singola applicazione, senza poter accedere alle altre parti del sistema operativo o ad altre funzioni. Questo ha portato a sperimentare diverse soluzioni per assicurarsi che l'applicazione resti sempre a schermo intero, tra cui la modalità "lock task" di Android e l'avvio automatico come applicazione launcher.

Il risultato di questa fase è stato un insieme di applicazioni-prototipo che sono state sperimentate sul campo durante alcune lezioni presso l'Università di Trento, permettendo di raccogliere importanti riscontri sul funzionamento del sistema.

A questo punto la fattibilità delle funzionalità di base che il sistema deve fornire sono state verificate, e i passi successivi hanno riguardato altri aspetti che possono migliorare il funzionamento del software.

Uno di questi è la possibilità di mettere in pausa e riprendere la registrazione. L'idea considerata è stata quella di non sospendere la registrazione ma di escludere in post-produzione i segmenti di video corrispondenti alle pause. Questo è agevolmente ottenibile grazie a \texttt{ffmpeg}, con l'aiuto di uno script che generi il comando (potenzialmente lungo) per il ritaglio dei segmenti.

Un'altra questione approfondita riguarda la sincronizzazione dei flussi, con lo scopo di evitare che l'audio risulti troppo sfasato rispetto al video, ed evitando quindi che sia visibile lo sfasamento tra voce registrata e il labiale del relatore. Il problema sorge principalmente per la presenza del video RTSP, la cui latenza è difficilmente stimabile\footnote{La latenza è influenzata dalla rete, dai tempi di codifica e dai buffer di trasmissione e ricezione. Non è quindi facile trovare un intervallo di tempo abbastanza preciso per sincronizzare il video con gli altri flussi.}. La soluzione sperimentale proposta prevede di incorporare l'audio nella registrazione video HDMI (in modo da ottenere una naturale sincronizzazione tra i due flussi), e di occuparsi invece di sincronizzare video HDMI e RTSP. L'implementazione sperimentale è stata ottenuta mostrando su schermo un marcatore visivo, che permetta di individuare con precisione un instante comune tra i due flussi video, e di conseguenza sincronizzarli.

Come accennato, una funzione del sistema LODE prevede che lo studente possa prendere appunti in tempo reale durante lo svolgimento delle lezioni, anche catturando degli screenshot di quanto proiettato in quel momento. Per evitare di inviare inutilmente screenshot al server nel caso in cui non ci sia stato nessun cambiamento percepibile nell'immagine, un sistema intelligente potrebbe rilevare le differenze tra i fotogrammi per determinare se l'immagine è nuova o invariata. Dopo aver appurato empiricamente che il confronto di tutti i pixel di due fotogrammi potrebbe risultare computazionalmente dispendioso, un'alternativa è quella di scegliere con un fattore di casualità un numero limitato di pixel "salienti". A livello intuitivo, il metodo sviluppato realizza una griglia con un numero oscillante di righe e colonne, da cui viene estratto un numero limitato di pixel utilizzati per rilevare rapidamente le differenze tra i fotogrammi.

I capitoli di questa tesi approfondiscono più dettagliatamente gli aspetti, le problematiche e le soluzioni proposte che sono state sintetizzate in questo sommario.

%\begin{itemize}
%  \item scelta delle API di Android Camera o Camera2, per l'accesso all'input HDMI del dispositivo;
%  \item implementazione della registrazione di un flusso video RTSP, per poter acquisire una videocamera connessa in rete;
%  \item implementazione della registrazione del video HDMI in ingresso;
%  \item aggiunta della cattura di fotogrammi durante la registrazione della lezione;
%  \item	integrazione dell'applicazione con il web server che permette agli studenti di catturare screenshot;
%  \item	rilevamento della disconnessione e riconnessione dell'input HDMI, e del cambio risoluzione;
%  \item	realizzazione di una “kiosk mode”, in modo da impedire all'utilizzatore di uscire dall'applicazione o di compromettere il sistema o il dispositivo;
%  \item	realizzazione di uno script per ritagliare segmenti dei video registrati, per ottenere la funzionalità di pausa/ripresa della registrazione;
%  \item	sincronizzazione dei flussi video HDMI e RTSP, in particolare mediante l'uso di un marcatore visivo presente in entrambi i flussi;
%  \item	rilevamento ed estrazione delle “slide” dal video HDMI in post-produzione;
%  \item	rilevamento dei cambiamenti al flusso video HDMI, in modo da evitare di inviare al server screenshot che sono già stati inviati;
%  \item	registrazione di audio LPCM e compressione AAC.
%\end{itemize}

